{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Declarative Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is deep learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is a sub-field of machine learning focusing on **end-to-end** learnable models based on artificial neural networks with multiple layers. \n",
    "\n",
    "These neural networks can learn to recognize patterns and make decisions based on input data, without being explicitly programmed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: end-to-end means the model learns the entire mapping from input to output, generally speaking we put the raw original data into the model and directly get the output, the model is usually artificial neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data-flow diagram of an ANN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's think of a deep learning model as a data-flow diagram:\n",
    "\n",
    "![data](data_flow.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how data is processed in a forward pass to arrive some predictions which can be written as:\n",
    "\n",
    "$$\n",
    "y = f_8\\left(f_4\\biggl(f_3\\biggl(f_2\\bigl(f_1(x)\\bigr)\\biggr)\\biggr), f_7\\biggl(f_6\\biggl(f_5\\bigl(f_1(x)\\bigr)\\biggr)\\biggr)\\right)\n",
    "$$\n",
    "\n",
    "This defines the output of the network as a composition of functions, each function takes its input as the parent node in the graph\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each processing node in the diagram is responsible for two primary operations:\n",
    "\n",
    "* Compute the output of its input and parameters in the forward pass\n",
    "* Compute the gradient of the error signal which respect to its input and parameters given the error signal's gradient which respect to its output in the backward pass\n",
    "\n",
    "As long as the node can compute the gradient of its output respect to its input, the error signal's gradient can be computed via the chain rule differentiation all the way from the output of the network to its inputs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dl_layer.png\"  width=\"70%\" height=\"30%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The forward and backward passes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a node that implements the Babylonian algorithm:\n",
    "\n",
    "<img src=\"bbln_pseudo.png\"  width=\"40%\" height=\"30%\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then back-propagate gradients as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_t}{\\partial y_{t-1}} = \\frac{1}{2} \\left( 1-\\frac{x}{y^2_{t-1}} \\right) \n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial y_t}{\\partial x} = \\frac{1}{2y_{t-1}}+\\frac{\\partial y_t}{\\partial y_{t-1}}\\frac{\\partial y_{t-1}}{\\partial x}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the node that implements the Babylonian algorithm computes:\n",
    "\n",
    "$$\n",
    "y = \\sqrt{x}\n",
    "$$\n",
    "\n",
    "The backward function then can be calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{y}}{\\partial{x}} &= \\frac{1}{2\\sqrt{x}}\\\\\n",
    "&= \\frac{1}{2y}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "fwd_fcn = x ** 0.5\n",
    "fwd_fcn.backward(x)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"autograd_example.png\" width=70% height=30%>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the forward and backward pass can be decoupled. \n",
    "\n",
    "Auto-differentiation is an amazing tool to allow us to write forward functions and get the gradients automatically computed. \n",
    "\n",
    "But this can be inefficient when the forward functions can not be expressed in closed form. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't have to use the automatic differentiation. \n",
    "\n",
    "We can separate the implementation details of the forward and backward passes as long as the backward pass can compute the gradient or even the descent direction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 [PyTorch training loop](https://github.com/mrdbourke/pytorch-deep-learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training loop, we'll build the following steps:\n",
    "\n",
    "| Number | Step name | What does it do? | Code example |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
    "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` | \n",
    "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
    "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
    "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |\n",
    "\n",
    "<!-- ![pytorch training loop annotated](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-training-loop-annotated.png) -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Different NN's architechure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZo19High.png\" width=75%>\n",
    "\n",
    "This graph can be found and downloaded at https://www.asimovinstitute.org/neural-network-zoo/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow](https://www.tensorflow.org) has also built an website where you can [play](https://playground.tensorflow.org/) with simple NN in your browser."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Implicit functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most deep learning model we can see, there is an explicit definition of the output of the node given its input. \n",
    "\n",
    "That is, we can usually write down a mathematical expression or a simple non-iterative method that will compute the output given the input.\n",
    "\n",
    "However for the implicit functions, the input and output satisfy a relationship but the output is not given directly by the input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"implicit_example.png\" width=70%>\n",
    "\n",
    "$$\n",
    "\\psi (x, y) = \\left(x-y^2_1+y^2_2\\right)^2 + \\left(y^2_1+y^2_2-1\\right)^2\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given the input $x$, we need a method to find the corresponding $y_1$ and $y_2$ that satisfy the implicit function jointly with $x$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set $\\psi(x, y) = 0$ to have a look at the solution space\n",
    "\n",
    "<img src=\"soln_space.png\" width=70%>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: links input x to output y and constraints y to lie on a circle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 The DDNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional deep learning architechure is a composition of simple feed-forward processing functions that are explicitly defined.\n",
    "\n",
    "When it comes to deep learning models with embedded differentiable optimization problems inside.\n",
    "\n",
    "We can use the form of optimization problem to represent the previous implicit function:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_y \\quad & \\left(x-y_1^2+y_2^2\\right)^2 \\\\\n",
    "\\text{subject to} \\quad & \\| y \\|^2  = 1 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"d_node.png\" width=50%>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 The applicaiton of deep declarative nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ddn_diagram.png\">\n",
    "\n",
    "$$\n",
    "y = f_8\\left(f_4\\biggl(\\text{argmin}f_3\\biggl(f_2\\bigl(f_1(x)\\bigr)\\biggr)\\biggr), \\text{argmin}f_7\\biggl(f_6\\biggl(f_5\\bigl(f_1(x)\\bigr)\\biggr)\\biggr)\\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Backward propagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we can solve the optimzation problem in the forward pass, the main question in DDNs is now how to calculate the backward pass \n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\text{argmin}_{u\\in C(x)}f(x, u)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the nice property of implicit function theorem and the KKT conditions, we can find the soution set $Y(x):\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ defined by $x \\in \\mathbb{R}^n$ as\n",
    "\n",
    "$$\n",
    "Y(x) = \\text{argmin}_u \\{ f(x, u): h(x, u) = 0_p, g(x, u) \\leq 0_q \\}\n",
    "$$\n",
    "\n",
    "and its corresponding derivative \n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = H^{-1}A^\\top (AH^{-1}A^\\top)(AH^{-1}B-C)-H^{-1}B\n",
    "$$\n",
    "\n",
    "A detailed proof can be found in [\"Deep Declarative Networks: A New Hope\"](https://arxiv.org/abs/1909.04866)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 A quick sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whe main difference between deep declarative nodes and tradition nodes is in forward and backward passes.\n",
    "\n",
    "* Forward pass\n",
    "    * A method to solve the optimization problem\n",
    "* Backward pass\n",
    "    * Optimality conditions\n",
    "    * Cached result from the forward pass\n",
    "    * Do **not** need to know how the problem was solved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Mean-Variance optimization problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. A quick recap of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Let's consider a portfolio with two assets, each has it's mean-variance $(ER_i, \\sigma_i) \\text{ with } i \\in {0, 1}$ and investment share $\\omega$, $(1 - \\omega)$. -->\n",
    "\n",
    "The mean-variance of asset one $(ER_1, \\sigma_1)$ and asset two $(ER_2, \\sigma_2)$ with investment share $\\omega$, $(1 - \\omega)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "ER_p &= \\omega ER_1 + (1 - \\omega)ER_2 \\\\\n",
    "\\sigma_p &= \\sqrt{\\omega^2 \\sigma^2 + (1-\\omega)^2 \\sigma^2 + 2\\omega(1-\\omega)\\rho_{12}\\sigma_1\\sigma_2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\rho$ is the correlation between the two investments.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the \"minimum-variance frontier\" of portfolios that have minimum variance for a given mean return.\n",
    "\n",
    "Let $\\omega$ be a vector of portfolio weight and $R$ be a vector of asset returns with mean $\\bar{R}$, then,\n",
    "\n",
    "* the return is $\\omega^\\top R$\n",
    "* the variance is \n",
    "  $$\n",
    "  \\mathbb{E} [(\\omega^\\top R - \\omega^\\top \\bar{R})(\\omega^\\top R - \\omega^\\top \\bar{R})^\\top] = \\omega^\\top \\Sigma \\omega\n",
    "  $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can form a simple LCQP in the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_\\omega \\quad & \\frac{1}{2} \\omega^\\top \\Sigma \\omega \\\\\n",
    "\\text{subject to} \\quad & \\omega^\\top \\bar{R} = \\mu \\\\\n",
    "& \\omega^\\top \\bold{1} = 1 \\\\\n",
    "& \\omega \\geq 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A general approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve such a convex optimization problem, we usually use the Lagrangian to find the optima:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\omega, \\lambda) = \\frac{1}{2}\\omega^\\top\\Sigma\\omega - \\lambda_1(\\omega^\\top\\bar{R} - \\mu) - \\lambda_2(\\omega^\\top \\bold{1} - 1) - \\nu^\\top\\omega\n",
    "$$\n",
    "\n",
    "We can then take the derivative of $\\mathcal{L}$ with respect to $\\omega$ and solve for the optima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some problems where we have really complex constraints, we can then try to find the corresponding dual problem:\n",
    "\n",
    "$$\n",
    "g(\\lambda, \\nu) = \\inf_\\omega \\left(\\frac{1}{2}\\omega^\\top\\Sigma\\omega - \\lambda_1(\\omega^\\top\\bar{R} - \\mu) - \\lambda_2(\\omega^\\top \\bold{1} - 1) - \\nu^\\top\\omega \\right)\n",
    "$$\n",
    "\n",
    "and then converting it to the Lagrangian dual problem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max \\quad & g(\\lambda, \\nu) \\\\\n",
    "\\text{subject to} \\quad & \\lambda \\geq 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can give us nice properties like weak/strong duality and the Slater's condition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Using `cvxpy` to find the optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal portfolio weights: [3.41827307e-01 2.09131868e-01 1.14245153e-07 2.14426701e-01\n",
      " 2.34614011e-01]\n",
      "Optimal variance: 0.0007644343727108283\n",
      "Expected return: 0.1999999998751394\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Define the problem data\n",
    "n = 5  # number of assets\n",
    "r = np.array([0.1, 0.2, 0.15, 0.25, 0.3]).T  # expected returns\n",
    "r_bar = np.average(r)\n",
    "mu = r_bar\n",
    "Sigma = np.array([[0.005, -0.010,  0.004,  0.001,  0.002],\n",
    "                  [-0.010,  0.040, -0.015, -0.005, -0.010],\n",
    "                  [0.004, -0.015,  0.023,  0.007,  0.008],\n",
    "                  [0.001, -0.005,  0.007,  0.010,  0.003],\n",
    "                  [0.002, -0.010,  0.008,  0.003,  0.015]])  # covariance matrix\n",
    "alpha = 0.5  # risk aversion parameter\n",
    "\n",
    "# Define the variables and constraints\n",
    "w = cp.Variable(n)\n",
    "objective = cp.Minimize(alpha * cp.quad_form(w, Sigma))\n",
    "constraints = [w @ r == mu, cp.sum(w) == 1, w >= 0]\n",
    "\n",
    "# Solve the problem\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(requires_grad=True)\n",
    "problem.backward()\n",
    "\n",
    "# Print the optimal portfolio weights and objective value\n",
    "print(f\"Optimal portfolio weights: {w.value}\")\n",
    "print(f\"Optimal variance: {problem.value}\")\n",
    "print(f\"Expected return: {w.value @ r}\")\n",
    "print(w.gradient)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A DDNs approach to the mean-variance optimization problem "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Creating a deep declarative node from package `ddn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddn.basic.node import *\n",
    "import warnings\n",
    "import scipy.optimize as opt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MinKLNode(GeneralConstDeclarativeNode):\n",
    "    def __init__(self, n):\n",
    "        pass\n",
    "\n",
    "    def objective(self, x):\n",
    "        return alpha * np.dot(np.dot(x.T, Sigma), x)\n",
    "\n",
    "    def constraint1(self, x):\n",
    "        return np.dot(np.ones((1, n)), x) - 1\n",
    "\n",
    "    def constraint2(self, x):\n",
    "        return np.dot(r, x) - r_bar\n",
    "\n",
    "    def solve(self):\n",
    "        # Solve the constrained optimization problem using scipy's built-in minimize function. Here we\n",
    "        # initialize the solver at the uniform distribution.\n",
    "        x0 = np.abs(np.random.randn(n).T)\n",
    "        x0 = x0/np.sum(x0)\n",
    "        constraints = [{'type': 'eq', 'fun': self.constraint1},\n",
    "                       {'type': 'eq', 'fun': self.constraint2},\n",
    "                       {'type': 'ineq', 'fun': lambda x: x}]\n",
    "        result = opt.minimize(self.objective, x0, constraints=constraints)\n",
    "\n",
    "        # The solve function must always return two arguments, the solution and context (i.e., cached values needed\n",
    "        # for computing the gradient). In the case of linearly constrained problems we do not need the dual solution\n",
    "        # in computing the gradient so we return None for context.\n",
    "        return result.x, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: [3.41827307e-01 2.09131868e-01 1.14245153e-07 2.14426701e-01\n",
      " 2.34614011e-01]\n",
      "Actual output:   [0.3443664  0.21106371 0.         0.20040699 0.2441629 ]\n"
     ]
    }
   ],
   "source": [
    "# test the node\n",
    "node = MinKLNode(5)\n",
    "y, _ = node.solve()\n",
    "print(f\"Expected Output: {w.value}\")\n",
    "print(f\"Actual output:   {y}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 A simple implementation of deep declarative nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007928073406219482\n",
      "tensor([0.2864, 0.4396, 0.4022, 0.3414, 0.2546])\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Define the loss function\n",
    "class PortfolioVarianceLoss(torch.nn.Module):\n",
    "    def forward(self, weights, cov_matrix):\n",
    "        variance = torch.matmul(torch.matmul(weights, cov_matrix), weights.T)\n",
    "        return variance\n",
    "\n",
    "# Define the optimizer\n",
    "model = Net(5, 5, 5)\n",
    "loss_fn = PortfolioVarianceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "cov_matrix = torch.from_numpy(Sigma).float()\n",
    "inputs = torch.from_numpy(r).float()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, cov_matrix)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add constraints\n",
    "    with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param.clamp_(0, 1)\n",
    "            weight_norm = model.fc1.weight/model.fc1.weight.sum(dim=1, keepdim=True)\n",
    "            model.fc1.weight.copy_(weight_norm)\n",
    "            weight_norm = model.fc2.weight/model.fc2.weight.sum(dim=1, keepdim=True)\n",
    "            model.fc2.weight.copy_(weight_norm)    \n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, cov_matrix)\n",
    "    print(loss.item())\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
